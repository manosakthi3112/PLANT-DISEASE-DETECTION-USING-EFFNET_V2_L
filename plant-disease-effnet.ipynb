{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":182633,"sourceType":"datasetVersion","datasetId":78313}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"  # Reduce fragmentation\n\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torchvision import models\nfrom torch.utils.data import DataLoader\n\n# Use CUDA if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Dataset path\ntrain = \"/kaggle/input/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/train\"\n\n# Load pretrained model\nmodel = models.efficientnet_v2_l(pretrained=True)\n\n# Modify classifier for your dataset\nnum_classes = len(os.listdir(train))\nmodel.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\nmodel= nn.DataParallel(model).to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.0001,betas=(0.5, 0.999))  # 10x smaller learning rate\n\n\n# Optional: Mixed precision to reduce memory usage\nfrom torch.cuda.amp import autocast, GradScaler\nscaler = GradScaler()\n\n# Transformations\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\n# Dataset and DataLoader\ntrain_dataset = datasets.ImageFolder(root=train, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=2,pin_memory=True)  # ⬅️ Reduced batch size\n\n# Training loop\nnum_epochs = 15\nmodel.train()\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        with autocast():  # ⬅️ Mixed precision\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += loss.item()\n\n    avg_loss = running_loss / len(train_loader)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n    torch.save(model.state_dict(),f\"{avg_loss} {epoch}.pth\")\n# Save model\nprint(\"Model saved to efficientnet_model.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T08:46:15.937888Z","iopub.execute_input":"2025-04-18T08:46:15.938368Z","iopub.status.idle":"2025-04-18T10:50:28.305766Z","shell.execute_reply.started":"2025-04-18T08:46:15.938343Z","shell.execute_reply":"2025-04-18T10:50:28.305011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}